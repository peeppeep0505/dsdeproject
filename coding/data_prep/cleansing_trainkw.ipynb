{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18573 entries, 0 to 18572\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   title          18573 non-null  object \n",
      " 1   authors        18573 non-null  object \n",
      " 2   affiliations   18573 non-null  object \n",
      " 3   citedby        18573 non-null  float64\n",
      " 4   mainterms      18573 non-null  object \n",
      " 5   subject_areas  18573 non-null  object \n",
      " 6   publisher      18562 non-null  object \n",
      " 7   Year           18573 non-null  int64  \n",
      "dtypes: float64(1), int64(1), object(6)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('finalscrap.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   title         1000 non-null   object\n",
      " 1   authors       1000 non-null   object\n",
      " 2   affiliations  1000 non-null   object\n",
      " 3   citedby       1000 non-null   int64 \n",
      " 4   publisher     1000 non-null   object\n",
      " 5   Year          1000 non-null   int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 47.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df = df[[\"title\", \"Year\", \"citedby\"]].rename(columns={\"Year\": \"year\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df2 = df2[[\"title\", \"Year\", \"citedby\"]].rename(columns={\"Year\": \"year\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([selected_df, selected_df2], ignore_index=True)\n",
    "# แปลงตัวอักษรในคอลัมน์ 'title' ให้เป็นตัวเล็กทั้งหมด\n",
    "combined_df['title'] = combined_df['title'].str.lower()\n",
    "combined_df = combined_df.drop_duplicates()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 19517 entries, 0 to 19572\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   title    19517 non-null  object \n",
      " 1   year     19517 non-null  int64  \n",
      " 2   citedby  19517 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 609.9+ KB\n"
     ]
    }
   ],
   "source": [
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   title  year  citedby\n",
      "0      [public, health, and, international, epidemiol...  2018      1.0\n",
      "1      [flexible, printed, active, antenna, for, digi...  2018      1.0\n",
      "2      [parametric, study, of, hydrogen, production, ...  2018     21.0\n",
      "3      [superhydrophobic, coating, from, fluoroalkyls...  2018     37.0\n",
      "4      [electrochemical, dna, sensor, using, pyrrolid...  2018     68.0\n",
      "...                                                  ...   ...      ...\n",
      "19568  [use, of, letibotulinumtoxina, for, aesthetic,...  2023      2.0\n",
      "19569  [green, composite, sponge, of, natural, rubber...  2023      7.0\n",
      "19570  [evaluation, of, foot, and, mouth, disease, co...  2023      3.0\n",
      "19571  [tracing, the, new, variant, in, the, communit...  2023     23.0\n",
      "19572  [utilisation, of, sunflower, marble, waste, na...  2023      2.0\n",
      "\n",
      "[19517 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# แยกคำในคอลัมน์ 'title' และลบคำที่ไม่ใช่ตัวอักษรภาษาอังกฤษ\n",
    "combined_df['title'] = combined_df['title'].apply(lambda x: [word for word in x.split() if re.match('^[a-zA-Z]+$', word)])\n",
    "\n",
    "# แสดงผลลัพธ์\n",
    "print(combined_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   title  year  citedby\n",
      "0      [public, health, and, international, epidemiol...     1      1.0\n",
      "1      [flexible, printed, active, antenna, for, digi...     1      1.0\n",
      "2      [parametric, study, of, hydrogen, production, ...     1     21.0\n",
      "3      [superhydrophobic, coating, from, fluoroalkyls...     1     37.0\n",
      "4      [electrochemical, dna, sensor, using, pyrrolid...     1     68.0\n",
      "...                                                  ...   ...      ...\n",
      "19568  [use, of, letibotulinumtoxina, for, aesthetic,...     6      2.0\n",
      "19569  [green, composite, sponge, of, natural, rubber...     6      7.0\n",
      "19570  [evaluation, of, foot, and, mouth, disease, co...     6      3.0\n",
      "19571  [tracing, the, new, variant, in, the, communit...     6     23.0\n",
      "19572  [utilisation, of, sunflower, marble, waste, na...     6      2.0\n",
      "\n",
      "[19517 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# สร้าง dictionary mapping ปีเป็นค่าตัวเลข\n",
    "year_mapping = {2018: 1, 2019: 2, 2020: 3, 2021: 4, 2022: 5, 2023: 6, 2024: 7}\n",
    "\n",
    "# แปลงปีให้เป็นค่าตัวเลข\n",
    "combined_df['year'] = combined_df['year'].map(year_mapping)\n",
    "\n",
    "# แสดงผลลัพธ์\n",
    "print(combined_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               word  predicted_citedby\n",
      "0             aaron          -0.006660\n",
      "1               aas           2.992919\n",
      "2                ab           6.769951\n",
      "3           abalone           1.672210\n",
      "4         abamectin           0.989324\n",
      "...             ...                ...\n",
      "22059            zu          -0.016016\n",
      "22060   zuckerkandl           0.992778\n",
      "22061      zwischen          27.986387\n",
      "22062  zwitterionic           5.004296\n",
      "22063       zymogen          -0.007215\n",
      "\n",
      "[22064 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# ใช้ title ที่แยกคำแล้ว (คุณทำไว้แล้ว)\n",
    "# แปลง title เป็นข้อความเดียวเพื่อให้ CountVectorizer สามารถทำงานได้\n",
    "combined_df['title'] = combined_df['title'].apply(lambda x: ' '.join(x))  # ถ้า 'title' เป็น list ของคำ\n",
    "\n",
    "# แปลง 'title' ด้วย CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(combined_df['title'])\n",
    "\n",
    "# กำหนด 'citedby' เป็น target\n",
    "y = combined_df['citedby']\n",
    "\n",
    "# สร้างโมเดลและฝึกด้วยข้อมูล\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# ทำนายค่า 'citedby' สำหรับแต่ละแถวใน DataFrame\n",
    "predicted_citedby = model.predict(X)\n",
    "\n",
    "# แปลงคำที่แยกจาก 'title' เป็นคอลัมน์\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# สร้าง DataFrame ที่เก็บคำและค่าทำนาย 'citedby' สำหรับแต่ละคำ\n",
    "words_and_predicted_citedby = []\n",
    "\n",
    "# ทำนายค่า citedby สำหรับแต่ละคำ\n",
    "for i, word in enumerate(feature_names):\n",
    "    # คำนวณค่า predicted_citedby สำหรับทุกแถวที่มีคำนี้\n",
    "    word_indices = np.where(X[:, i].toarray() > 0)[0]  # หาแถวที่มีคำนี้\n",
    "    word_predicted_citedby = predicted_citedby[word_indices]\n",
    "    \n",
    "    # เก็บคำและค่าทำนาย\n",
    "    for j, value in zip(word_indices, word_predicted_citedby):\n",
    "        words_and_predicted_citedby.append({\n",
    "            'word': word,\n",
    "            'predicted_citedby': value\n",
    "        })\n",
    "\n",
    "# สร้าง DataFrame จากข้อมูล\n",
    "df_words_citedby = pd.DataFrame(words_and_predicted_citedby)\n",
    "\n",
    "# คำนวณค่าเฉลี่ยของ predicted_citedby สำหรับแต่ละคำที่ซ้ำกัน\n",
    "df_avg_citedby = df_words_citedby.groupby('word')['predicted_citedby'].mean().reset_index()\n",
    "\n",
    "# แสดงผลตารางที่ไม่มีคำซ้ำ\n",
    "print(df_avg_citedby)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_citedby.to_csv(\"samplepredict.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

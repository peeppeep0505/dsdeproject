{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjAkFncg-J3Z"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HONtv9Ka-UHp",
        "outputId": "8793156d-7d63-4afb-a3f1-349e1af756f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mv: cannot move 'spark-3.3.2-bin-hadoop3' to 'spark/spark-3.3.2-bin-hadoop3': Directory not empty\n"
          ]
        }
      ],
      "source": [
        "if IN_COLAB:\n",
        "    !apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "    !wget -q https://archive.apache.org/dist/spark/spark-3.3.2/spark-3.3.2-bin-hadoop3.tgz\n",
        "    !tar xf spark-3.3.2-bin-hadoop3.tgz\n",
        "    !mv spark-3.3.2-bin-hadoop3 spark\n",
        "    !pip install -q findspark\n",
        "    import os\n",
        "    os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "    os.environ[\"SPARK_HOME\"] = \"/content/spark\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdRmbue7-VsF"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wWd1Pjn-Vmy"
      },
      "outputs": [],
      "source": [
        "spark_url = 'local'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTRBfWOI-XPK"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from itertools import combinations\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql.functions import col, from_json, expr, explode, struct, count\n",
        "from pyspark.sql.types import ArrayType, StringType\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kPeHKPy-WtM"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder\\\n",
        "        .master(spark_url)\\\n",
        "        .appName('Spark SQL')\\\n",
        "        .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 293,
      "metadata": {
        "id": "pXLcJnCy-aSN"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import sum, avg, min, max, count, desc, explode, split, regexp_replace, round, format_number\n",
        "import re\n",
        "\n",
        "path = '2023authornet.csv'\n",
        "df = spark.read.csv(path, header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 294,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmcIpq14dyb5",
        "outputId": "326bfc7f-555c-4c11-eee0-ef0fe6e86420"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- authors: string (nullable = true)\n",
            " |-- citedby: string (nullable = true)\n",
            " |-- author_count: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 295,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIcxCN9pbvux",
        "outputId": "f081ce9a-dd6a-4839-8181-6586d405b5f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[summary: string, authors: string, citedby: string, author_count: string]"
            ]
          },
          "metadata": {},
          "execution_count": 295
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 296,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDEmiLWj-oYp",
        "outputId": "1fa27795-ef71-4182-8b1a-a86080c957f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------+------------+\n",
            "|             authors|citedby|author_count|\n",
            "+--------------------+-------+------------+\n",
            "|['Boobphahom S.',...|    0.0|           2|\n",
            "|['Chauhan C.', 'K...|    0.0|           7|\n",
            "|['Satanwat P.', '...|    0.0|           8|\n",
            "|['Buakaew T.', 'R...|    0.0|           2|\n",
            "|['Patchaiyappan A...|    0.0|           8|\n",
            "+--------------------+-------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 297,
      "metadata": {
        "id": "K-C1UNFWZrn5"
      },
      "outputs": [],
      "source": [
        "filtered_data = df.withColumn('cited-by', df.citedby.cast('int')).drop('_c0', 'citedby')\n",
        "df_cleaned = filtered_data[filtered_data['cited-by'] > 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 298,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFEa36aw_CKB",
        "outputId": "ce101cea-4f0d-4b61-d4d5-eb25ce37ea8e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "375"
            ]
          },
          "metadata": {},
          "execution_count": 298
        }
      ],
      "source": [
        "df_cleaned.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 299,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--9t2WyI70hG",
        "outputId": "6a8990eb-548d-4af8-9151-dbdb330df41c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------+--------+\n",
            "|             authors|author_count|cited-by|\n",
            "+--------------------+------------+--------+\n",
            "|['Sereewatthanawu...|           4|       4|\n",
            "|['Mahardawi B.', ...|           7|       2|\n",
            "|['Umpreecha C.', ...|           4|       2|\n",
            "|['Wahyuni D.K.', ...|           8|       2|\n",
            "|['Nim B.', 'Rahay...|           9|       2|\n",
            "+--------------------+------------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_cleaned.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 300,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ptvbi6RGYEa",
        "outputId": "c7b4f834-892d-4c11-9345-2b1d59d7fb79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- node1: string (nullable = true)\n",
            " |-- node2: string (nullable = true)\n",
            " |-- weight: long (nullable = false)\n",
            "\n",
            "+--------------------+------------------+------+\n",
            "|               node1|             node2|weight|\n",
            "+--------------------+------------------+------+\n",
            "|            Ament Z.|          Patki A.|     2|\n",
            "|Jirawattanasomkul T.|  Likitlersuang S.|     2|\n",
            "|        Aliyu A.A.A.|         Shinjo J.|     2|\n",
            "|        Ratchahat S.| Assabumrungrat S.|     2|\n",
            "|          Bhave V.M.|        Irvin M.R.|     2|\n",
            "|      Wiriyakijja P.|          Villa A.|     2|\n",
            "|        Motlagh S.R.|         Khezri R.|     2|\n",
            "|           Inkong K.|          Linga P.|     2|\n",
            "|           Jafari S.|       Worobo R.W.|     2|\n",
            "|              Fan Y.|            Qin J.|     2|\n",
            "|             Chen Z.|           Wang Q.|     2|\n",
            "|      Al-Rubaye H.T.|           Maes M.|     3|\n",
            "|            Kumar V.|          Duhan L.|     2|\n",
            "|  Kijpaisalratana N.|        Irvin M.R.|     2|\n",
            "|             Yang C.|          Zhang X.|     3|\n",
            "|         Kantavat P.|        Hayashi Y.|     2|\n",
            "|     Jiaranuchart S.|       Mattheos N.|     2|\n",
            "|         Kamsuwan C.|Chalermsinsuwan B.|     2|\n",
            "|      Asdornwised W.|    Chaitusaney S.|     2|\n",
            "|      Piumsomboon P.|Chalermsinsuwan B.|     2|\n",
            "+--------------------+------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "authors_schema = ArrayType(StringType())\n",
        "\n",
        "df_with_authors_array = df_cleaned.withColumn(\"authors\", from_json(col(\"authors\"), authors_schema))\n",
        "filtered_rows = df_with_authors_array.filter(expr(\"size(authors) > 1\"))\n",
        "\n",
        "edges = filtered_rows.rdd.flatMap(\n",
        "    lambda row: [Row(node1=a, node2=b) for a, b in combinations(row[\"authors\"], 2)]\n",
        ")\n",
        "\n",
        "edges_df = spark.createDataFrame(edges)\n",
        "edges_weighted = edges_df.groupBy(\"node1\", \"node2\").count().withColumnRenamed(\"count\", \"weight\")\n",
        "\n",
        "filtered_edges = edges_weighted.filter(col(\"weight\") > 1)\n",
        "filtered_edges.printSchema()\n",
        "filtered_edges.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 301,
      "metadata": {
        "id": "LgLrCpFatKpl"
      },
      "outputs": [],
      "source": [
        "filtered_edges_without_weight = filtered_edges.drop(\"weight\")\n",
        "filtered_edges_without_weight.toPandas().to_csv('filtered_authorship_2023.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}